{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44ef7071",
   "metadata": {},
   "source": [
    "## Introduction to Basic Pytorch \n",
    "\n",
    "Before diving deep in pytorch lightning let us focus on Pytorch as Lightning just enables us to wrap pytorch code to train and deploy Pytorch at scale. Hence in this tutorial let us focus in learning some survival skills. Such as,\n",
    "\n",
    "1. Data Manipulation and processing \n",
    "2. Linear Algebra \n",
    "3. Differentiation\n",
    "\n",
    "### Data Manipulation \n",
    "\n",
    "In order to train neural networks we need to ingest data and manipulate data. Let us get our hands dirty with n-dimensional data. As, most of the manipulation on n-dimensional arrays such as tensors will be much similar to the popular scientific computing library such as numpy this section of the chapter will be breeze for most of our audience. Only two differences are that one the tensor class supports automatic differentiation which is crucial for neural nets and two it leverages GPU to accelerate the computation, where as numpy only supports CPU's. Let us go ahead and start our tutorials on subsections of Data Manipulation. \n",
    "\n",
    "Note: Please refer to Detailed documentation of [pytorch](https://docs.pytorch.org/docs/stable/torch.html) for more details. \n",
    "\n",
    "#### Tensor Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae01d7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor x: tensor([0, 1, 2, 3, 4, 5, 6, 7])\n",
      "Shape of x: torch.Size([8])\n",
      "Data type of x: torch.int64\n",
      "Type of x: <class 'torch.Tensor'>\n",
      "Tensor y: tensor([0.0000, 0.0526, 0.1053, 0.1579, 0.2105, 0.2632, 0.3158, 0.3684, 0.4211,\n",
      "        0.4737, 0.5263, 0.5789, 0.6316, 0.6842, 0.7368, 0.7895, 0.8421, 0.8947,\n",
      "        0.9474, 1.0000])\n",
      "Shape of y: torch.Size([20])\n",
      "Data type of y: torch.float32\n",
      "Type of y: <class 'torch.Tensor'>\n",
      "Zeros Tensor:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Ones Tensor:\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "Random Tensor:\n",
      " tensor([[0.4276, 0.5639, 0.3950],\n",
      "        [0.7499, 0.3426, 0.2318],\n",
      "        [0.4370, 0.9344, 0.6116]])\n",
      "Tensor from List:\n",
      " tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "#  creating a tensor whuch is evenly spaced between 0 and 7\n",
    "x = torch.arange(start=0, end = 8, step = 1)\n",
    "\n",
    "print(\"Tensor x:\", x)\n",
    "\n",
    "print(\"Shape of x:\", x.shape)\n",
    "\n",
    "print(\"Data type of x:\", x.dtype)\n",
    "\n",
    "print(\"Type of x:\", type(x))\n",
    "\n",
    "# creating tensor with equal spacing between 0 and 1\n",
    "y = torch.linspace(start =0, end=1, steps=20, dtype=torch.float32)\n",
    "# linspace auto computes tuthe number of steps based on the start and stop values\n",
    "print(\"Tensor y:\", y)\n",
    "print(\"Shape of y:\", y.shape)\n",
    "print(\"Data type of y:\", y.dtype)\n",
    "print(\"Type of y:\", type(y))\n",
    "\n",
    "# Create a tensor filled with zeros\n",
    "zeros_tensor = torch.zeros(3, 3)\n",
    "print(\"Zeros Tensor:\\n\", zeros_tensor)\n",
    "\n",
    "# Create a tensor filled with ones\n",
    "ones_tensor = torch.ones(3, 3)\n",
    "print(\"Ones Tensor:\\n\", ones_tensor)\n",
    "\n",
    "# Create a tensor with random values\n",
    "random_tensor = torch.rand(3, 3)\n",
    "print(\"Random Tensor:\\n\", random_tensor)\n",
    "\n",
    "# Create a tensor with specified values\n",
    "tensor_from_list = torch.tensor([[1, 2], [3, 4]])\n",
    "print(\"Tensor from List:\\n\", tensor_from_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1244515f",
   "metadata": {},
   "source": [
    "#### What are Key Tensor Attributes\n",
    "\n",
    "1. **`.shape`** or **`.size()`**:\n",
    "   - **Description**: Returns the shape of the tensor as a `torch.Size` object, which is a subclass of a tuple.\n",
    "   - **Example**:\n",
    "     ```python\n",
    "     tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "     print(\"Shape:\", tensor.shape)\n",
    "     print(\"Size:\", tensor.size())\n",
    "     ```\n",
    "\n",
    "2. **`.dtype`**:\n",
    "   - **Description**: Returns the data type of the tensor elements.\n",
    "   - **Example**:\n",
    "     ```python\n",
    "     tensor = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "     print(\"Data Type:\", tensor.dtype)\n",
    "     ```\n",
    "\n",
    "3. **`.device`**:\n",
    "   - **Description**: Indicates the device (CPU or GPU ) on which the tensor is allocated.\n",
    "   - **Example**:\n",
    "     ```python\n",
    "     tensor = torch.tensor([1, 2, 3])\n",
    "     print(\"Device (CPU):\", tensor.device)\n",
    "\n",
    "     tensor_gpu = torch.tensor([1, 2, 3], device='cuda')\n",
    "     print(\"Device (GPU):\", tensor_gpu.device)\n",
    "      # for GPU allocation on M1, M2, M3 \n",
    "     if torch.backends.mps.is_available():\n",
    "      tensor_mps = torch.tensor([1, 2, 3], device='mps')\n",
    "      print(\"Device (MPS):\", tensor_mps.device)\n",
    "     ```\n",
    "\n",
    "4. **`.requires_grad`**:\n",
    "   - **Description**: Indicates whether the tensor requires gradient computation. This is essential for training neural networks.\n",
    "   - **Example**:\n",
    "     ```python\n",
    "     tensor = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "     print(\"Requires Grad:\", tensor.requires_grad)\n",
    "     ```\n",
    "\n",
    "5. **`.grad`**:\n",
    "   - **Description**: Holds the gradient of the tensor after backpropagation. This attribute is `None` for tensors that do not require gradients or before gradients are computed.\n",
    "   - **Example**:\n",
    "     ```python\n",
    "     tensor = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "     result = tensor * 2\n",
    "     result.sum().backward()\n",
    "     print(\"Gradient:\", tensor.grad)\n",
    "     ```\n",
    "\n",
    "6. **`.is_leaf`**:\n",
    "   - **Description**: Indicates whether the tensor is a leaf tensor. A leaf tensor is a tensor that is created by the user and not the result of an operation involving other tensors.\n",
    "   - **Example**:\n",
    "     ```python\n",
    "     a = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "     b = a * 2\n",
    "     print(\"Is Leaf (a):\", a.is_leaf)  # True\n",
    "     print(\"Is Leaf (b):\", b.is_leaf)  # False\n",
    "     ```\n",
    "\n",
    "7. **`.is_cuda`**:\n",
    "   - **Description**: Indicates whether the tensor is stored on the GPU.\n",
    "   - **Example**:\n",
    "     ```python\n",
    "     tensor_cpu = torch.tensor([1, 2, 3])\n",
    "     tensor_gpu = tensor_cpu.to('cuda')\n",
    "     print(\"Is CUDA (CPU Tensor):\", tensor_cpu.is_cuda)\n",
    "     print(\"Is CUDA (GPU Tensor):\", tensor_gpu.is_cuda)\n",
    "     ```\n",
    "\n",
    "8. **`.numel()`**:\n",
    "   - **Description**: Returns the total number of elements in the tensor.\n",
    "   - **Example**:\n",
    "     ```python\n",
    "     tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "     print(\"Number of Elements:\", tensor.numel())\n",
    "     ```\n",
    "\n",
    "9. **`.ndimension()`**:\n",
    "   - **Description**: Returns the number of dimensions of the tensor.\n",
    "   - **Example**:\n",
    "     ```python\n",
    "     tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "     print(\"Number of Dimensions:\", tensor.ndimension())\n",
    "     ```\n",
    "\n",
    "10. **`.stride()`**:\n",
    "    - **Description**: Returns the step in each dimension when traversing the tensor.\n",
    "    - **Example**:\n",
    "      ```python\n",
    "      tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "      print(\"Stride:\", tensor.stride())\n",
    "      ```\n",
    "\n",
    "**Important Notes**\n",
    "\n",
    "- **`.requires_grad=True`** is essential for enabling **automatic differentiation**, especially during training with optimizers like `torch.optim.SGD`. Without it, `.backward()` won’t track gradients.\n",
    "\n",
    "- **Specifying `device='cuda'` or `device='mps'`** ensures tensors are allocated on the **GPU (NVIDIA)** or **Apple Silicon GPU**, which can **drastically speed up training**. Mismatched device usage (e.g., mixing CPU and GPU tensors) will raise errors.\n",
    "\n",
    "- **Use `.to(device)`** or `.cuda()` / `.mps()` to move models and data to the appropriate computation device before training:\n",
    "  ```python\n",
    "  model.to(device)\n",
    "  input_tensor = input_tensor.to(device)\n",
    "\n",
    "#### Indexing and slicing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55822f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7499, 0.3426, 0.2318])\n",
      "tensor(0.6116)\n",
      "tensor([[0.4276, 0.5639],\n",
      "        [0.7499, 0.3426]])\n",
      "tensor([0.7499, 0.3426, 0.2318])\n",
      "tensor([0.5639, 0.3426, 0.9344])\n"
     ]
    }
   ],
   "source": [
    "# Retrieve an element from the tensor\n",
    "print(random_tensor[1])\n",
    "# retreive the last element of the tensor\n",
    "print(random_tensor[-1, -1])\n",
    "\n",
    "# Retrieve a slice of the tensor\n",
    "print(random_tensor[0:2, 0:2])  # First two rows and first two columns\n",
    "# Retrieve a specific row\n",
    "print(random_tensor[1, :])  # Second row\n",
    "# Retrieve a specific column\n",
    "print(random_tensor[:, 1])  # Second column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d79697",
   "metadata": {},
   "source": [
    "#### Basic Operations \n",
    "\n",
    "Now that we know how to create tensors, let us explore to perform some scalar operations on each element of tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9aaf514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor from List:\n",
      " tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "Addition:\n",
      " tensor([[3, 4],\n",
      "        [5, 6]])\n",
      "Subtraction:\n",
      " tensor([[0, 1],\n",
      "        [2, 3]])\n",
      "Multiplication:\n",
      " tensor([[ 3,  6],\n",
      "        [ 9, 12]])\n",
      "Division:\n",
      " tensor([[0.5000, 1.0000],\n",
      "        [1.5000, 2.0000]])\n",
      "Square:\n",
      " tensor([[ 1,  4],\n",
      "        [ 9, 16]])\n",
      "Apply exp for each element tensor([[ 2.7183,  7.3891],\n",
      "        [20.0855, 54.5982]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensor from List:\\n\", tensor_from_list)\n",
    "# Perform basic operations\n",
    "print(\"Addition:\\n\", tensor_from_list + 2)  # Add 2 to each element\n",
    "print(\"Subtraction:\\n\", tensor_from_list - 1)  # Subtract 1 from each element\n",
    "print(\"Multiplication:\\n\", tensor_from_list * 3)  # Multiply each element by 3\n",
    "print(\"Division:\\n\", tensor_from_list / 2)  # Divide each element by 2  \n",
    "print(\"Square:\\n\", tensor_from_list ** 2)  # Square each element\n",
    "print(\"Apply exp for each element\", tensor_from_list.exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d228d548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped Tensor:\n",
      " tensor([[0.4276, 0.5639, 0.3950, 0.7499, 0.3426, 0.2318, 0.4370, 0.9344, 0.6116]])\n",
      "Reshaped Tensor (9, 1):\n",
      " tensor([[0.4276],\n",
      "        [0.5639],\n",
      "        [0.3950],\n",
      "        [0.7499],\n",
      "        [0.3426],\n",
      "        [0.2318],\n",
      "        [0.4370],\n",
      "        [0.9344],\n",
      "        [0.6116]])\n",
      "Flattened Tensor:\n",
      " tensor([0.4276, 0.5639, 0.3950, 0.7499, 0.3426, 0.2318, 0.4370, 0.9344, 0.6116])\n",
      "Transposed Tensor:\n",
      " tensor([[0.4276, 0.7499, 0.4370],\n",
      "        [0.5639, 0.3426, 0.9344],\n",
      "        [0.3950, 0.2318, 0.6116]])\n",
      "Concatenated Tensor:\n",
      " tensor([1, 2, 3, 4, 5, 6])\n",
      "Verticle Stacked Tensor:\n",
      " tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "Split Tensor:\n",
      " (tensor([[0.4276, 0.5639, 0.3950],\n",
      "        [0.7499, 0.3426, 0.2318],\n",
      "        [0.4370, 0.9344, 0.6116]]),)\n",
      "Chunked Tensor:\n",
      " (tensor([[0.4276],\n",
      "        [0.7499],\n",
      "        [0.4370]]), tensor([[0.5639],\n",
      "        [0.3426],\n",
      "        [0.9344]]), tensor([[0.3950],\n",
      "        [0.2318],\n",
      "        [0.6116]]))\n"
     ]
    }
   ],
   "source": [
    "# Reshape a tensor\n",
    "reshaped_tensor = random_tensor.view(1, 9)\n",
    "print(\"Reshaped Tensor:\\n\", reshaped_tensor)\n",
    "# Reshape a tensor to a different shape\n",
    "reshaped_tensor_2 = random_tensor.reshape(9, 1)\n",
    "print(\"Reshaped Tensor (9, 1):\\n\", reshaped_tensor_2)\n",
    "# difference between view and reshape is that view returns a new tensor with the same data but different shape, \n",
    "# while reshape returns a new tensor with the same data but different shape and may copy the data if necessary.\n",
    "# Flatten a tensor\n",
    "flattened_tensor = random_tensor.flatten()\n",
    "print(\"Flattened Tensor:\\n\", flattened_tensor)\n",
    "\n",
    "# Transpose a tensor\n",
    "transposed_tensor = random_tensor.t()\n",
    "print(\"Transposed Tensor:\\n\", transposed_tensor)\n",
    "\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "# Concatenate tensors\n",
    "concatenated_tensor = torch.cat((a, b), dim=0)\n",
    "print(\"Concatenated Tensor:\\n\", concatenated_tensor)\n",
    "\n",
    "# example of verticle stacking \n",
    "verticle_stack= torch.stack([a,b],axis =1)\n",
    "print(\"Verticle Stacked Tensor:\\n\", verticle_stack)\n",
    "# example of splitting \n",
    "split_tensor = torch.split(tensor=random_tensor, split_size_or_sections=3, dim=0)\n",
    "print(\"Split Tensor:\\n\", split_tensor)\n",
    "\n",
    "# example of chunking \n",
    "\n",
    "chunk_tensor = random_tensor.chunk(chunks=3, dim=1)\n",
    "print(\"Chunked Tensor:\\n\", chunk_tensor)\n",
    "\n",
    "# difference between split and chunk is that split divides the tensor into equal parts,\n",
    "# while chunk divides the tensor into specified number of parts where they need not be equal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b2ed369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element-wise Comparison (Equal):\n",
      " tensor([False,  True, False])\n",
      "Element-wise Comparison (Greater than):\n",
      " tensor([False, False,  True])\n",
      "tensor([1, 2, 3]) tensor([3, 2, 1]) tensor([3, 2, 3])\n",
      "Selected Elements (using where):\n",
      " tensor([3, 2, 3])\n",
      "All elements are greater than 0:\n",
      " tensor(True)\n",
      "Any element is greater than 2:\n",
      " tensor(True)\n",
      "Masked Tensor (elements > 1):\n",
      " tensor([2, 3])\n",
      "Replaced Tensor (elements > 2 replaced with -1):\n",
      " tensor([ 1,  2, -1])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise comparison\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([3, 2, 1])\n",
    "comparison = torch.eq(a, b)\n",
    "print(\"Element-wise Comparison (Equal):\\n\", comparison)\n",
    "\n",
    "# Element-wise greater than comparison\n",
    "greater_than = torch.gt(a, b)\n",
    "print(\"Element-wise Comparison (Greater than):\\n\", greater_than)\n",
    "\n",
    "# Using torch.where to select elements based on condition\n",
    "condition = a > b\n",
    "selected_elements = torch.where(condition, a, b)\n",
    "print(a,b,selected_elements)\n",
    "print(\"Selected Elements (using where):\\n\", selected_elements)\n",
    "\n",
    "# conditional tensors \n",
    "# Check if all elements satisfy a condition\n",
    "all_elements_greater = torch.all(a > 0)\n",
    "print(\"All elements are greater than 0:\\n\", all_elements_greater)\n",
    "\n",
    "# Check if any element satisfies a condition\n",
    "any_element_greater = torch.any(a > 2)\n",
    "print(\"Any element is greater than 2:\\n\", any_element_greater)\n",
    "\n",
    "# Masking tensor elements based on condition\n",
    "masked_tensor = torch.masked_select(a, a > 1)\n",
    "print(\"Masked Tensor (elements > 1):\\n\", masked_tensor)\n",
    "\n",
    "# Replacing elements based on condition\n",
    "replaced_tensor = torch.where(a > 2, torch.tensor(-1), a)\n",
    "print(\"Replaced Tensor (elements > 2 replaced with -1):\\n\", replaced_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78db858a",
   "metadata": {},
   "source": [
    "#### Broadcasting \n",
    "\n",
    "We already understand how element wise binary operations are performed on two tensors of same shape. In some circumstances we can still perform element wise binary operations by invoking a boradcasting mechanism. It performs following two steps. \n",
    "\n",
    "1. Exand one or both the arrays by copying the element along axes to make both the arrays to same dimensions, it is a view and not a copy \n",
    "\n",
    "2.  It performs element wise operations let us see some examples below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca19a2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element-wise multiplication result:\n",
      " tensor([[ 10,  20,  30],\n",
      "        [400, 500, 600]])\n",
      "Broadcasting result:\n",
      " tensor([[11, 12],\n",
      "        [21, 22],\n",
      "        [31, 32]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])       # Shape: (2, 3)\n",
    "\n",
    "B = torch.tensor([[10],\n",
    "                  [100]])           # Shape: (2, 1)\n",
    "\n",
    "C = A * B\n",
    "\n",
    "print(\"Element-wise multiplication result:\\n\", C)\n",
    "# Broadcasting allows us to perform operations on tensors of different shapes.\n",
    "# In this case, B is broadcasted to match the shape of A during multiplication.\n",
    "# Broadcasting works by expanding the smaller tensor along the dimensions of the larger tensor. \n",
    "# Example of broadcasting\n",
    "A = torch.tensor([[10],\n",
    "                  [20],\n",
    "                  [30]])  # Shape: (3, 1)\n",
    "B = torch.tensor([[1, 2]])  # Shape: (1, 2)\n",
    "\n",
    "C = A + B\n",
    "print(\"Broadcasting result:\\n\", C)\n",
    "# Broadcasting allows us to perform operations on tensors of different shapes.\n",
    "# In this case, Both tensors are broadcasted to a common shape of (3, 2) during addition.\n",
    "# Broadcasting works by expanding the smaller tensor along the dimensions of the larger tensor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c84a4df",
   "metadata": {},
   "source": [
    "#### Saving Memory \n",
    "Running operations can cause new memory to be allocated to host results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23b479a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before operation, Y ID: 4378512944\n",
      "After operation, Y ID: 5754938064\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([1,2,3])\n",
    "Y = torch.tensor([4,5,6])\n",
    "before = id(Y)\n",
    "Y = Y + X\n",
    "after = id(Y)\n",
    "print(\"Before operation, Y ID:\", before)\n",
    "print(\"After operation, Y ID:\", after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79791ae",
   "metadata": {},
   "source": [
    "Above example specification is sometimes undesirable in machine learning as some times we want to update thousands of parameters which can duplicate the memory. Fortunately we can update the parameters using inplace operations without duplicating the memory such as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f57fdc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before inplace operation, Y ID: 5754938064\n",
      "After inplace operation, Y ID: 5754938064\n"
     ]
    }
   ],
   "source": [
    "before = id(Y)\n",
    "Y[:] = Y + X\n",
    "after = id(Y)\n",
    "\n",
    "print(\"Before inplace operation, Y ID:\", before)\n",
    "print(\"After inplace operation, Y ID:\", after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb23d937",
   "metadata": {},
   "source": [
    "#### Conversion to python objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d51c8684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Element Tensor to Python Object: 42 42.0 42\n",
      "Multi Element Tensor to Python List: [1, 2, 3, 4] [1, 2, 3, 4] (1, 2, 3, 4)\n",
      "Multi Element Tensor to Numpy Array: [1 2 3 4] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# conversion to python objects\n",
    "# We can convert a tensor to a Python object using the .item() method for single-element tensors or the .tolist() method for multi-element tensors.\n",
    "single_element_tensor = torch.tensor(42)\n",
    "multi_element_tensor = torch.tensor([1, 2, 3, 4]) \n",
    "\n",
    "# Convert single-element tensor to Python object\n",
    "single_element_value = single_element_tensor.item()\n",
    "print(\"Single Element Tensor to Python Object:\", single_element_value, float(single_element_value), int(single_element_value))\n",
    "# Convert multi-element tensor to Python list\n",
    "multi_element_list = multi_element_tensor.tolist()\n",
    "print(\"Multi Element Tensor to Python List:\", multi_element_list, list(multi_element_list), tuple(multi_element_list))\n",
    "# Convert multi-element tensor to numpy array\n",
    "multi_element_numpy = multi_element_tensor.numpy()\n",
    "print(\"Multi Element Tensor to Numpy Array:\", multi_element_numpy, type(multi_element_numpy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38b0a15",
   "metadata": {},
   "source": [
    "### Linear Algebra \n",
    "\n",
    "We have already seen lot of vector and scalar multiplications above such as manipulating one value is scalar manipulation and manipulation a group of scalars is vector manipulation, which is a fixed length of array. \n",
    "\n",
    "Just as scalars which are 0th order tensors, vectors are 1st order tensors, matrics are 2nd order tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00c194fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A:\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "Transposed Matrix A:\n",
      " tensor([[1, 4, 7],\n",
      "        [2, 5, 8],\n",
      "        [3, 6, 9]])\n"
     ]
    }
   ],
   "source": [
    "# some examples of matrix operations are \n",
    "\n",
    "A = torch.arange(1, 10).reshape(3, 3)\n",
    "\n",
    "print(\"Matrix A:\\n\", A)\n",
    "A =A.T\n",
    "\n",
    "print(\"Transposed Matrix A:\\n\", A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0b4d6e",
   "metadata": {},
   "source": [
    "#### Tensors \n",
    "\n",
    "Basically tensors with dimensions that are greater than 2nd order is called a Tensor, This is a generic way of describing the nth order arrays. These are more essential when we start working with images as they are generally 3rd order tensors. \n",
    "\n",
    "General Notation of a tensor is $X_{i,j,k}$ Where i,j,k denote the index of a element in each dimension specifically pointing to the spatial dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f04928b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14],\n",
       "         [15, 16, 17],\n",
       "         [18, 19, 20],\n",
       "         [21, 22, 23]],\n",
       "\n",
       "        [[24, 25, 26],\n",
       "         [27, 28, 29],\n",
       "         [30, 31, 32],\n",
       "         [33, 34, 35]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(36).reshape(3, 4, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1493f3",
   "metadata": {},
   "source": [
    "#### Reduction \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5147b41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of all elements: tensor(21)\n",
      "Sum along dim=0 (column-wise reduction): tensor([5, 7, 9])\n",
      "Sum along dim=1 (row-wise reduction): tensor([ 6, 15])\n",
      "Mean of all elements: tensor(3.5000)\n",
      "Mean along dim=1 (mean per row): tensor([2., 5.])\n",
      "Max values per row: tensor([3, 6])\n",
      "Max indices per row: tensor([2, 2])\n",
      "Min values per column: tensor([1, 2, 3])\n",
      "Min indices per column: tensor([0, 0, 0])\n",
      "Argmax along dim=0 (per column): tensor([1, 1, 1])\n",
      "Argmin along dim=1 (per row): tensor([0, 0])\n",
      "Product of elements: tensor(24)\n",
      "Standard Deviation: tensor(1.2910)\n",
      "Variance: tensor(1.6667)\n",
      "Sum with keepdim (preserve dim=1): tensor([[ 6],\n",
      "        [15]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])  # Shape: (2 rows, 3 columns)\n",
    "\n",
    "# 1. Sum\n",
    "print(\"Sum of all elements:\", torch.sum(x))  # → scalar\n",
    "print(\"Sum along dim=0 (row wise reduction):\", torch.sum(x, dim=0))  \n",
    "print(\"Sum along dim=1 (column wise reduction):\", torch.sum(x, dim=1))     \n",
    "\n",
    "# 2. Mean\n",
    "print(\"Mean of all elements:\", torch.mean(x.float()))\n",
    "print(\"Mean along dim=1 (mean per row):\", torch.mean(x.float(), dim=1))\n",
    "\n",
    "# 3. Max and Min\n",
    "max_vals, max_indices = torch.max(x, dim=1)  # max of each row (dim=1)\n",
    "print(\"Max values per row:\", max_vals)\n",
    "print(\"Max indices per row:\", max_indices)\n",
    "\n",
    "min_vals, min_indices = torch.min(x, dim=0)  # min of each column (dim=0)\n",
    "print(\"Min values per column:\", min_vals)\n",
    "print(\"Min indices per column:\", min_indices)\n",
    "\n",
    "# 4. Argmax and Argmin\n",
    "print(\"Argmax along dim=0 (per column):\", torch.argmax(x, dim=0))\n",
    "print(\"Argmin along dim=1 (per row):\", torch.argmin(x, dim=1))\n",
    "\n",
    "# 5. Product\n",
    "y = torch.tensor([1, 2, 3, 4])\n",
    "print(\"Product of elements:\", torch.prod(y))  # → scalar 24\n",
    "\n",
    "# 6. Standard Deviation and Variance\n",
    "z = torch.tensor([1.0, 2.0, 3.0, 4.0])\n",
    "print(\"Standard Deviation:\", torch.std(z))\n",
    "print(\"Variance:\", torch.var(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681f0f97",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "In the above example, axis and dimension refer to the same concept in PyTorch: they specify along which dimension the reduction is performed.\n",
    "\n",
    "For a tensor with n dimensions, each dimension is indexed from 0 to n-1.\n",
    "So when we specify dim=k in a reduction operation, the reduction is performed along the (k-th) dimension, affecting the elements across that axis.\n",
    "\n",
    "For example, In a tensor of shape (2, 3), dim=0 reduces across rows (column-wise), and dim=1 reduces across columns (row-wise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d820e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum with keepdim (preserve dim=1): tensor([[ 6],\n",
      "        [15]]) torch.Size([2, 1])\n",
      "Sum without keepdim (dim=1): tensor([ 6, 15]) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# 7. Keepdim Example\n",
    "\n",
    "sum_x = torch.sum(x, dim=1, keepdim=True)\n",
    "print(\"Sum with keepdim (preserve dim=1):\", sum_x, sum_x.shape )\n",
    "\n",
    "sum_y = torch.sum(x, dim=1)\n",
    "print(\"Sum without keepdim (dim=1):\", sum_y, sum_y.shape )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049a406c",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "As you can see, when keepdim=True is used, the original dimension is preserved in the result with size 1.\n",
    "This means the shape of sum_x will be (2, 1) instead of being reduced to (2,).\n",
    "\n",
    "This is especially useful for broadcasting in later operations, where you want to keep the tensor shape consistent for elementwise computation.\n",
    "\n",
    "If keepdim=False (default), the reduced dimension is removed entirely, which can make broadcasting harder or require reshaping.\n",
    "\n",
    "#### Dot Product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9efe6683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product: tensor(32)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "\n",
    "dot = torch.dot(a, b)\n",
    "print(\"Dot product:\", dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10800e9",
   "metadata": {},
   "source": [
    "The dot product is a reduction operation that multiplies two vectors elementwise and then sums the result:\n",
    "\n",
    "$$\n",
    "\\text{dot}(a, b) = (1 \\times 4) + (2 \\times 5) + (3 \\times 6) = 4 + 10 + 18 = 32\n",
    "$$\n",
    "\n",
    "In PyTorch, `torch.dot()` is used specifically for **1D tensors (vectors)** of equal length.  \n",
    "It returns a **scalar (0-D tensor)** as the result.\n",
    "\n",
    "This is different from **elementwise multiplication** (`a * b`) or **matrix multiplication** (`torch.matmul` or `@`), which preserve dimensions.\n",
    "\n",
    "---\n",
    "\n",
    "##### Dot Product Applications\n",
    "\n",
    "Dot products are useful in a wide range of contexts.  \n",
    "For example, given a vector of values **x** and a vector of weights **w**,  \n",
    "the **weighted sum** of the values in **x** according to the weights **w** can be expressed as the dot product:\n",
    "\n",
    "$$\n",
    "\\mathbf{x} \\cdot \\mathbf{w} = \\sum_{i=1}^n x_i w_i\n",
    "$$\n",
    "\n",
    "##### Weighted Average\n",
    "\n",
    "When the weights are **nonnegative** and **sum to 1**, i.e.,\n",
    "\n",
    "$$\n",
    "w_i \\geq 0 \\quad \\text{for all } i, \\quad \\text{and} \\quad \\sum_{i=1}^n w_i = 1,\n",
    "$$\n",
    "\n",
    "the dot product $\\mathbf{x} \\cdot \\mathbf{w}$ expresses a **weighted average** of the elements in $\\mathbf{x}$.\n",
    "\n",
    "##### Cosine Similarity\n",
    "As\n",
    "\n",
    "$$\n",
    "\\text{dot}(a, b) = \\|a\\| \\cdot \\|b\\| \\cos(\\theta)\n",
    "$$\n",
    "After **normalizing** two vectors $\\mathbf{a}$ and $\\mathbf{b}$ to have unit length:\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{a}\\| = \\|\\mathbf{b}\\| = 1,\n",
    "$$\n",
    "\n",
    "their dot product becomes:\n",
    "\n",
    "$$\n",
    "\\mathbf{a} \\cdot \\mathbf{b} = \\cos(\\theta)\n",
    "$$\n",
    "\n",
    "where $\\theta$ is the angle between the two vectors.  \n",
    "This gives a **cosine similarity** measure ranging from $-1$ to $1$.\n",
    "\n",
    "We will formally introduce this notion of **vector length** (also called the **L2 norm**) later in this section.\n",
    "\n",
    "#### Matrix Multiplication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a9408c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of A @ B:\n",
      " tensor([[ 70,  80,  90],\n",
      "        [158, 184, 210],\n",
      "        [246, 288, 330]])\n",
      "Shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define 2 matrices\n",
    "A = torch.arange(1, 13).view(3,4)   # Shape: (3, 4)\n",
    "\n",
    "B = torch.arange(1, 13).view(4,3)   # Shape: (4, 3)\n",
    "\n",
    "# Matrix multiplication\n",
    "C = torch.matmul(A, B)       # or: C = A @ B\n",
    "\n",
    "print(\"Result of A @ B:\\n\", C)\n",
    "print(\"Shape:\", C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f25dccf",
   "metadata": {},
   "source": [
    "\n",
    "Matrix multiplication involves taking the **dot product** of rows from the first matrix with columns from the second matrix.\n",
    "\n",
    "If:\n",
    "- Matrix **A** has shape $(m \\times n)$\n",
    "- Matrix **B** has shape $(n \\times p)$  \n",
    "Then:\n",
    "- The result **C = A @ B** will have shape $(m \\times p)$\n",
    "\n",
    "##### Equation\n",
    "\n",
    "$$\n",
    "C_{ij} = \\sum_{k=1}^{n} A_{ik} \\cdot B_{kj}\n",
    "$$\n",
    "\n",
    "That is, each element $C_{ij}$ in the result matrix is the dot product of:\n",
    "- The **i-th row** of matrix **A**\n",
    "- The **j-th column** of matrix **B**\n",
    "\n",
    "#### Norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb9287c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 Norm (Manhattan Distance): tensor(7.)\n",
      "L2 Norm (Euclidean Distance): tensor(5.)\n"
     ]
    }
   ],
   "source": [
    "# Define a vector\n",
    "v = torch.tensor([3.0, -4.0])\n",
    "\n",
    "# L1 norm: sum of absolute values\n",
    "l1_norm = torch.norm(v, p=1)\n",
    "print(\"L1 Norm (Manhattan Distance):\", l1_norm)\n",
    "\n",
    "# L2 norm: square root of sum of squares\n",
    "l2_norm = torch.norm(v, p=2)\n",
    "print(\"L2 Norm (Euclidean Distance):\", l2_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b74289",
   "metadata": {},
   "source": [
    "In deep learning, we are often trying to solve the optimization problems by maximizing the probability assigned to observed data or minimize the distance between predictions and the ground truth observations. The above mentioned distances, are often helpful to contruct the objectives of deep learning algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd6afc7",
   "metadata": {},
   "source": [
    "### Automatic differentiation \n",
    "\n",
    "While teaching full calculus is out of scope for this course, we will focus on the basics of automatic differentiation — a powerful tool that PyTorch provides to handle gradient computation automatically.\n",
    "\n",
    "Gradients are essential for optimizing neural networks using methods like gradient descent. In PyTorch, we don’t need to manually compute partial derivatives. Instead, PyTorch tracks operations and uses reverse-mode automatic differentiation during .backward() calls.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f6384fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx: tensor(14.)\n"
     ]
    }
   ],
   "source": [
    "# Scalar example\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x ** 3 + 2 * x + 1   # Define a simple function\n",
    "y.backward()             # Computes dy/dx\n",
    "print(\"dy/dx:\", x.grad)  # Output: 3x^2 + 2 = 3*4 + 2 = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6bbffd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx: tensor([2., 4., 6.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "y = (x ** 2).sum()  # y = x₁² + x₂² + x₃²\n",
    "y.backward()\n",
    "print(\"dy/dx:\", x.grad)  # dy/dx = 2x → [2., 4., 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53cd8c7",
   "metadata": {},
   "source": [
    "##### detach \n",
    "In PyTorch, detach() is used to stop a tensor from tracking operations for gradient computation. This is useful when:\n",
    "- You want to freeze a tensor so it won’t affect gradient updates.\n",
    "- You need to convert a tensor to a NumPy array without tracking gradients.\n",
    "- You want to reuse a value from a forward pass without backpropagating through it again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80b3059d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requires grad for z: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "y = x * 2\n",
    "\n",
    "# z requires grad\n",
    "z = y.detach()  # z shares data with y, but has no autograd history\n",
    "print(\"Requires grad for z:\", z.requires_grad)  # False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df8b5b7",
   "metadata": {},
   "source": [
    "##### In place gradient reset \n",
    "\n",
    "After each .backward() call, gradients accumulate (i.e., they are added, not overwritten).\n",
    "To avoid incorrect gradient updates, you must zero the gradients manually before the next backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd1180b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients: tensor([2., 4., 6.])\n",
      "Gradients: tensor([ 4.,  8., 12.])\n",
      "Gradients: tensor([2., 4., 6.])\n",
      "Gradients: tensor([2., 4., 6.])\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "\n",
    "for _ in range(2):\n",
    "    y = (w ** 2).sum()\n",
    "    y.backward()\n",
    "    print(\"Gradients:\", w.grad)  # Accumulates across iterations\n",
    "    #w.grad.zero_() #\n",
    "w.grad.zero_() # Reset gradients to zero before next iteration\n",
    "for _ in range(2):\n",
    "    y = (w ** 2).sum()\n",
    "    y.backward()\n",
    "    print(\"Gradients:\", w.grad)  # Accumulates across iterations\n",
    "    w.grad.zero_() #with zero of gradients "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739f55fa",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "### Notable Resources. \n",
    "\n",
    "While we cannot completely cover the Pytorch functions and class, Please use the below mentioned resources to explore pytorch documentation and tutorials to explore the use case of Pytorch API\n",
    "\n",
    "1. [Pytorch Documentation](https://docs.pytorch.org/docs/stable/index.html)\n",
    "2. [d2l](https://d2l.ai/chapter_preliminaries/index.html)\n",
    "3. [Pytorch Tutorials](https://docs.pytorch.org/tutorials/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightning_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
